# -*- coding: utf-8 -*-
"""Project_Maths.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IiJYTJmofVoEuI3hREQUzicRAif5Dw5e
"""

# %% [code]
!pip install -q numpy matplotlib scikit-image opencv-python medpy seaborn

# %% [code]
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from skimage import data, img_as_float, filters, restoration, segmentation, util
from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr
from medpy.filter.smoothing import anisotropic_diffusion
import cv2
import pandas as pd
import time

# Configure styles
sns.set_style("whitegrid")
plt.rcParams.update({'font.size': 12})

# %% [code]
class ImageProcessor:
    def __init__(self, image):
        self.original = img_as_float(image)
        self.noisy = self._add_noise()
        self.metrics = []

    def _add_noise(self):
        """Add mixed Gaussian & Salt-and-Pepper noise"""
        np.random.seed(42)
        noisy = util.random_noise(self.original, mode='gaussian', var=0.01)
        return util.random_noise(noisy, mode='s&p', amount=0.05)

    def _edge_preservation(self, processed):
        """Improved edge preservation metric"""
        orig_edges = filters.canny(self.original, sigma=1)
        proc_edges = filters.canny(processed, sigma=1)
        return np.mean(orig_edges == proc_edges)

    def _calculate_metrics(self, processed, method_type, is_seg=False):
        """Calculate comprehensive metrics"""
        return {
            'Method': method_type[0],
            'Type': method_type[1],
            'SSIM': ssim(self.original, processed, data_range=1.0) if not is_seg else np.nan,
            'PSNR': psnr(self.original, processed, data_range=1.0) if not is_seg else np.nan,
            'Edge Preservation': self._edge_preservation(processed) if not is_seg else np.nan,
            'Dice': self._dice_coefficient(processed) if is_seg else np.nan,
            'Time (s)': processed[1],
            'Output': processed[0]
        }

    def _dice_coefficient(self, processed):
        """Segmentation accuracy metric"""
        truth = self.original > 0.5
        return 2 * np.logical_and(truth, processed).sum() / (truth.sum() + processed.sum())

# %% [code]
class TraditionalMethods(ImageProcessor):
    def run(self):
        methods = {
            'Gaussian': lambda: (filters.gaussian(self.noisy, sigma=1.5), 0),
            'Median': lambda: (filters.median(self.noisy, np.ones((3,3))), 0),
            'Bilateral': lambda: (cv2.bilateralFilter((self.noisy*255).astype(np.uint8), 9, 75, 75)/255.0, 0),
            'Threshold': lambda: ((self.noisy > 0.5).astype(float), 0)
        }
        return self._process_methods(methods, 'Traditional')

# %% [code]
class PDEMethods(ImageProcessor):
    def run(self):
        methods = {
            'Heat Eq': self._heat_equation,
            'Perona-Malik': self._perona_malik,
            'Total Variation': self._total_variation,
            'Level Set': self._level_set
        }
        return self._process_methods(methods, 'PDE')

    def _heat_equation(self):
        start = time.time()
        img = self.noisy.copy()
        for _ in range(100):
            img += 0.05 * filters.laplace(img)
        return np.clip(img, 0, 1), time.time() - start

    def _perona_malik(self):
        start = time.time()
        return anisotropic_diffusion(self.noisy, niter=50, kappa=30), time.time() - start

    def _total_variation(self):
        start = time.time()
        return restoration.denoise_tv_chambolle(self.noisy, weight=0.15), time.time() - start

    def _level_set(self):
        start = time.time()
        return segmentation.chan_vese(self.noisy, mu=0.25, max_num_iter=200), time.time() - start

!pip install -q scikit-image

# %% [code]
# Add missing imports
from skimage.feature import canny
from skimage import util
from skimage import morphology

# Revised ImageProcessor class
class ImageProcessor:
    def __init__(self, image):
        self.original = img_as_float(image)
        self.noisy = self._add_noise()

    def _add_noise(self):
        """Create realistic mixed noise"""
        np.random.seed(42)
        noisy = util.random_noise(self.original, mode='gaussian', var=0.01)
        return util.random_noise(noisy, mode='s&p', amount=0.05)

    def _edge_preservation(self, processed):
        """Calculate edge similarity using Canny"""
        orig_edges = canny(self.original, sigma=1)  # Fixed import
        proc_edges = canny(processed, sigma=1)
        return np.mean(orig_edges == proc_edges)

    def _dice_coefficient(self, processed):
        """Calculate segmentation accuracy"""
        truth = self.original > 0.5
        return 2 * np.logical_and(truth, processed).sum() / (truth.sum() + processed.sum())

# %% [code]
# Revised TraditionalProcessor class
class TraditionalProcessor(ImageProcessor):
    def run(self):
        results = []

        # Gaussian Blur
        start = time.time()
        gaussian = filters.gaussian(self.noisy, sigma=1.5)
        results.append(self._create_result('Gaussian Blur', gaussian, start))

        # Median Filter
        start = time.time()
        # Import morphology and use it here
        median = filters.median(self.noisy, morphology.disk(3))
        results.append(self._create_result('Median Filter', median, start))

        # Bilateral Filter
        start = time.time()
        bilateral = cv2.bilateralFilter((self.noisy*255).astype(np.uint8), 9, 75, 75)/255.0
        results.append(self._create_result('Bilateral', bilateral, start))

        # Thresholding
        start = time.time()
        threshold = (self.noisy > 0.5).astype(float)
        results.append({
            'Method': 'Thresholding',
            'Type': 'Traditional',
            'SSIM': ssim(self.original, threshold, data_range=1.0),
            'PSNR': psnr(self.original, threshold, data_range=1.0),
            'Edge': self._edge_preservation(threshold),
            'Dice': self._dice_coefficient(threshold),
            'Time': time.time() - start,
            'Output': threshold
        })

        return pd.DataFrame(results)

    def _create_result(self, name, processed, start):
        return {
            'Method': name,
            'Type': 'Traditional',
            'SSIM': ssim(self.original, processed, data_range=1.0),
            'PSNR': psnr(self.original, processed, data_range=1.0),
            'Edge': self._edge_preservation(processed),
            'Dice': np.nan,
            'Time': time.time() - start,
            'Output': processed
        }
# %% [code]
# PDE Methods Implementation
class PDEProcessor(ImageProcessor):
    def run(self):
        results = []

        # Heat Equation
        heat = self._heat_equation()
        results.append(heat)

        # Perona-Malik
        pm = self._perona_malik()
        results.append(pm)

        # Total Variation
        tv = self._total_variation()
        results.append(tv)

        # Level Set
        levelset = self._level_set()
        results.append(levelset)

        return pd.DataFrame(results)

    def _heat_equation(self):
        start = time.time()
        img = self.noisy.copy()
        for _ in range(100):
            img += 0.05 * filters.laplace(img)
        processed = np.clip(img, 0, 1)
        return self._create_pde_result('Heat Equation', processed, start)

    def _perona_malik(self):
        start = time.time()
        processed = anisotropic_diffusion(self.noisy, niter=50, kappa=30)
        return self._create_pde_result('Perona-Malik', processed, start)

    def _total_variation(self):
        start = time.time()
        processed = restoration.denoise_tv_chambolle(self.noisy, weight=0.15)
        return self._create_pde_result('Total Variation', processed, start)

    def _level_set(self):
        start = time.time()
        processed = segmentation.chan_vese(self.noisy, mu=0.25, max_num_iter=200)
        return {
            'Method': 'Level Set',
            'Type': 'PDE',
            'SSIM': np.nan,
            'PSNR': np.nan,
            'Edge': np.nan,
            'Dice': self._dice_coefficient(processed),
            'Time': time.time() - start,
            'Output': processed
        }

    def _create_pde_result(self, name, processed, start):
        return {
            'Method': name,
            'Type': 'PDE',
            'SSIM': ssim(self.original, processed, data_range=1.0),
            'PSNR': psnr(self.original, processed, data_range=1.0),
            'Edge': self._edge_preservation(processed),
            'Dice': np.nan,
            'Time': time.time() - start,
            'Output': processed
        }

# %% [code]
# Execute the processing
processor = ImageProcessor(data.camera())
traditional_df = TraditionalProcessor(processor.original).run()
pde_df = PDEProcessor(processor.original).run()
results = pd.concat([traditional_df, pde_df]).reset_index(drop=True)

# Enhanced Visualization 1: Radar Chart
def create_radar_chart(df):
    # Change the categories to match the column names in the DataFrame
    categories = ['SSIM', 'PSNR', 'Edge', 'Dice', 'Time']
    fig = plt.figure(figsize=(8, 8))
    ax = fig.add_subplot(111, polar=True)

    for idx, row in df.iterrows():
        values = row[categories].fillna(0).tolist()
        values += values[:1]
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist() + [0]
        ax.plot(angles, values, linewidth=2, label=row['Method'])
        ax.fill(angles, values, alpha=0.25)

    ax.set_theta_offset(np.pi / 2)
    ax.set_theta_direction(-1)
    # Change the labels to the desired display names
    ax.set_thetagrids(np.degrees(angles[:-1]), ['SSIM', 'PSNR', 'Edge Preservation', 'Dice', 'Time (s)'])
    plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
    plt.title("Multi-Metric Comparison Radar Chart")
    plt.show()

create_radar_chart(results)

# Enhanced Visualization 2: Performance Evolution
def plot_metric_evolution():
    fig, axs = plt.subplots(2, 2, figsize=(15, 10))

    # SSIM vs PSNR
    sns.scatterplot(data=results, x='SSIM', y='PSNR', hue='Type', style='Type', ax=axs[0,0], s=100)
    axs[0,0].set_title("SSIM vs PSNR Correlation")

    # Edge Preservation vs Time
    # Changed 'Edge Preservation' to 'Edge' to match the column name in the DataFrame
    sns.barplot(data=results, x='Method', y='Edge', hue='Type', ax=axs[0,1])
    axs[0,1].set_title("Edge Preservation by Method")
    axs[0,1].tick_params(axis='x', rotation=45)

    # Time Comparison
    # Changed 'Time (s)' to 'Time' to match the column name in the DataFrame
    sns.lineplot(data=results, x='Method', y='Time', hue='Type', ax=axs[1,0], marker='o')
    axs[1,0].set_title("Processing Time Comparison")
    axs[1,0].tick_params(axis='x', rotation=45)

    # Segmentation Accuracy
    seg_data = results.dropna(subset=['Dice'])
    sns.violinplot(data=seg_data, x='Type', y='Dice', ax=axs[1,1])
    axs[1,1].set_title("Segmentation Accuracy Distribution")

    plt.tight_layout()
    plt.show()

plot_metric_evolution()

# Enhanced Visualization 3: Image Comparison Grid
def create_image_grid(results):
    fig = plt.figure(figsize=(20, 15))
    grid = plt.GridSpec(4, 5, hspace=0.3, wspace=0.2)

    # Original Images
    ax1 = fig.add_subplot(grid[0, 0])
    ax1.imshow(processor.original, cmap='gray')
    ax1.set_title("Original Image")

    ax2 = fig.add_subplot(grid[0, 1])
    ax2.imshow(processor.noisy, cmap='gray')
    ax2.set_title("Noisy Input")

    # Method Results
    for idx, (_, row) in enumerate(results.iterrows()):
        ax = fig.add_subplot(grid[(idx//3)+1, idx%3])
        if row['Method'] == 'Level Set':
            ax.imshow(processor.original, cmap='gray')
            ax.contour(row['Output'], colors='red', linewidths=0.8)
            ax.set_title(f"{row['Type']}: {row['Method']}\nDice: {row['Dice']:.2f}")
        else:
            ax.imshow(row['Output'], cmap='gray')
            ax.set_title(f"{row['Type']}: {row['Method']}\nSSIM: {row['SSIM']:.2f}")
        ax.axis('off')

    # Metric Comparison
    # Changed 'Edge Preservation' to 'Edge' to match column name
    ax_metrics = fig.add_subplot(grid[1:, 3:])
    sns.heatmap(results[['SSIM', 'PSNR', 'Edge']].corr(),  # Corrected column name
                annot=True, cmap='viridis', ax=ax_metrics)
    ax_metrics.set_title("Metric Correlation Matrix")

    plt.show()

create_image_grid(results)

# %% [code]
# Enhanced Visualization 4: Parameter Sensitivity Analysis
def parameter_sensitivity():
    weights = np.linspace(0.05, 0.3, 10)
    metrics = []

    for w in weights:
        start = time.time()
        tv = restoration.denoise_tv_chambolle(processor.noisy, weight=w)
        metrics.append({
            'Weight': w,
            'SSIM': ssim(processor.original, tv, data_range=1.0),
            'PSNR': psnr(processor.original, tv, data_range=1.0),
            'Time': time.time() - start
        })

    df = pd.DataFrame(metrics)
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(df['Weight'], df['SSIM'], label='SSIM')
    ax.plot(df['Weight'], df['PSNR'], label='PSNR')
    ax.set_xlabel("TV Weight Parameter")
    ax.set_ylabel("Metric Value")
    ax2 = ax.twinx()
    ax2.plot(df['Weight'], df['Time'], color='red', linestyle='--', label='Time')
    ax2.set_ylabel("Execution Time (s)")
    fig.legend(loc="upper right", bbox_to_anchor=(0.9, 0.9))
    plt.title("Total Variation Parameter Sensitivity Analysis")
    plt.show()

parameter_sensitivity()